#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ç³»çµ±ã®æ±ç”¨ã‚¯ãƒ©ã‚¹ç¾¤
sklearnäº’æ›ã®ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å¯¾å¿œ
"""

import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, TransformerMixin


class DataQualityValidator(BaseEstimator, TransformerMixin):
    """ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼ãƒ»ä¿®å¾©"""

    def __init__(self, fix_dtypes=True, drop_high_missing=0.5, drop_zero_variance=True):
        self.fix_dtypes = fix_dtypes
        self.drop_high_missing = drop_high_missing
        self.drop_zero_variance = drop_zero_variance
        self.columns_to_drop = []

    def fit(self, X, y=None):
        self.columns_to_drop = []

        if self.drop_high_missing:
            missing_ratio = X.isnull().mean()
            high_missing_cols = missing_ratio[missing_ratio > self.drop_high_missing].index.tolist()
            self.columns_to_drop.extend(high_missing_cols)
            print(f"ğŸ—‘ï¸ é«˜æ¬ æç‡ã‚«ãƒ©ãƒ å‰Šé™¤å¯¾è±¡: {high_missing_cols}")

        if self.drop_zero_variance:
            numeric_cols = X.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if col not in self.columns_to_drop and X[col].var() == 0:
                    self.columns_to_drop.append(col)
                    print(f"ğŸ—‘ï¸ åˆ†æ•£ã‚¼ãƒ­ã‚«ãƒ©ãƒ å‰Šé™¤å¯¾è±¡: {col}")

        return self

    def transform(self, X):
        X_new = X.copy()

        # é«˜æ¬ æãƒ»åˆ†æ•£ã‚¼ãƒ­ã‚«ãƒ©ãƒ å‰Šé™¤
        if self.columns_to_drop:
            X_new = X_new.drop(columns=self.columns_to_drop, errors='ignore')
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªæ¤œè¨¼å®Œäº†: {len(self.columns_to_drop)}ã‚«ãƒ©ãƒ å‰Šé™¤")

        return X_new


class DtypeOptimizer(BaseEstimator, TransformerMixin):
    """ãƒ‡ãƒ¼ã‚¿å‹æœ€é©åŒ–"""

    def __init__(self, model_name=None, force_dtype=None):
        self.model_name = model_name
        self.force_dtype = force_dtype
        self.dtype_map = {}

    def fit(self, X, y=None):
        self.dtype_map = {}

        # LightGBMç­‰ã¯å…ƒã®dtypeã‚’ç¶­æŒ
        if self.model_name in ['LGBMClassifier', 'LGBMRegressor']:
            print(f"ğŸ“Š {self.model_name}: å…ƒãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¶­æŒ")
            return self

        # å¼·åˆ¶æŒ‡å®šãŒã‚ã‚‹å ´åˆ
        if self.force_dtype:
            numeric_cols = X.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                self.dtype_map[col] = self.force_dtype
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‹å¼·åˆ¶å¤‰æ›: {self.force_dtype}")
        else:
            # è‡ªå‹•æœ€é©åŒ–
            for col in X.select_dtypes(include=[np.number]).columns:
                if X[col].dtype == 'float64':
                    if (X[col] == X[col].astype('float32')).all():
                        self.dtype_map[col] = 'float32'

        return self

    def transform(self, X):
        X_new = X.copy()

        for col, dtype in self.dtype_map.items():
            if col in X_new.columns:
                X_new[col] = X_new[col].astype(dtype)

        if self.dtype_map:
            print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿å‹æœ€é©åŒ–å®Œäº†: {len(self.dtype_map)}ã‚«ãƒ©ãƒ å¤‰æ›")

        return X_new