{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ matplotlib設定完了\n"
     ]
    }
   ],
   "source": [
    "# matplotlib設定\n",
    "import logging\n",
    "import matplotlib\n",
    "\n",
    "# フォント警告抑制\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "\n",
    "# DejaVu Sansフォント設定\n",
    "matplotlib.rcParams['font.family'] = 'DejaVu Sans'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Ubuntu']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ matplotlib設定完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps実験実行ノートブック\n",
    "\n",
    "config駆動のMLOpsパイプライン実験を実行します。\n",
    "\n",
    "## セル構成\n",
    "1. **Import** - 必要なライブラリとモジュールのインポート\n",
    "2. **データ読み込み・分割** - CSVデータの読み込みとtrain/test分割\n",
    "3. **MLflow実行** - パイプライン構築、学習、評価、記録\n",
    "4. **予測結果の確認と活用** - 予測結果DataFrameの確認と後続分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ライブラリインポート完了\n"
     ]
    }
   ],
   "source": [
    "# 基本ライブラリ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import mlflow\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# データ処理ユーティリティ\n",
    "from src.utils.data_utils import get_dataset_name, detect_task_type, load_csv_data\n",
    "from src.utils.cv_utils import create_cv_strategy\n",
    "\n",
    "# components機能インポート\n",
    "from src.mlops.components.pipeline import create_pipeline\n",
    "from src.mlops.components.visualization import create_visualizations\n",
    "from src.mlops.components.optimization import OptunaOptimizer\n",
    "from src.mlops.components.artifacts import (\n",
    "    save_model_artifacts, log_experiment_metrics, \n",
    "    setup_mlflow_experiment, set_mlflow_tags, \n",
    "    log_config_parameters, log_runtime_parameters,\n",
    "    create_prediction_dataframe, save_prediction_results\n",
    ")\n",
    "\n",
    "print(\"✅ ライブラリインポート完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Config読み込み・データ分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Config読み込み完了\n",
      "  - Pipeline: universal_features\n",
      "  - Model: lightgbm\n",
      "  - CV Strategy: {'module': 'sklearn.model_selection', 'class': 'StratifiedKFold', 'params': {'n_splits': 3, 'shuffle': True, 'random_state': '${globals.random_state}'}}\n",
      "  - Optuna: 有効\n"
     ]
    }
   ],
   "source": [
    "# Config読み込み（Hydraの代わりにOmegaConfで直接読み込み）\n",
    "cfg = OmegaConf.load(\"config/config.yaml\")\n",
    "\n",
    "# pipelines設定を読み込んでマージ\n",
    "pipeline_config = OmegaConf.load(f\"config/pipelines/{cfg.defaults[2].pipelines}.yaml\")\n",
    "cfg = OmegaConf.merge(cfg, pipeline_config)\n",
    "\n",
    "# models設定を読み込んでマージ\n",
    "model_config = OmegaConf.load(f\"config/models/classification/{cfg.defaults[1]['models/classification']}.yaml\")\n",
    "cfg = OmegaConf.merge(cfg, model_config)\n",
    "\n",
    "# notebookディレクトリからの相対パス修正\n",
    "cfg.data.file_path = f\"{cfg.data.file_path}\"\n",
    "\n",
    "print(\"📋 Config読み込み完了\")\n",
    "print(f\"  - Pipeline: {cfg.defaults[2].pipelines}\")\n",
    "print(f\"  - Model: {cfg.defaults[1]['models/classification']}\")\n",
    "print(f\"  - CV Strategy: {cfg.evaluation.cv_strategy}\")\n",
    "print(f\"  - Optuna: {'有効' if cfg.optuna.enabled else '無効'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 データ読み込み開始\n",
      "📊 CSV: _data/raw/wine_classification.csv - Shape: (178, 15) - Features: 13 - Classes: 3\n",
      "✅ データ準備完了\n",
      "  - データセット: _data/raw/wine_classification.csv\n",
      "  - データ形状: (178, 15)\n",
      "  - 特徴量数: 13\n",
      "  - タスクタイプ: classification\n",
      "  - Train/Test: 142/36\n"
     ]
    }
   ],
   "source": [
    "# データ読み込み\n",
    "print(\"📊 データ読み込み開始\")\n",
    "df, feature_cols, target_names = load_csv_data(cfg)\n",
    "\n",
    "# データ分割\n",
    "X = df[feature_cols]\n",
    "y = df[cfg.data.target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=cfg.data.test_size,\n",
    "    random_state=cfg.data.random_state\n",
    ")\n",
    "\n",
    "# タスクタイプ判定\n",
    "task_type = detect_task_type(y)\n",
    "\n",
    "print(f\"✅ データ準備完了\")\n",
    "print(f\"  - データセット: {cfg.data.file_path}\")\n",
    "print(f\"  - データ形状: {df.shape}\")\n",
    "print(f\"  - 特徴量数: {len(feature_cols)}\")\n",
    "print(f\"  - タスクタイプ: {task_type}\")\n",
    "print(f\"  - Train/Test: {len(X_train)}/{len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MLflow実験実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 MLflow実験開始\n",
      "  - Experiment: config_driven_mlops\n",
      "  - Run name: stratified_cv_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-22 23:02:12,857] A new study created in memory with name: ml_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Run ID: 1563ac16\n",
      "\n",
      "🎯 Optuna最適化開始\n",
      "🎯 Optuna最適化開始 | 2 trials | maximize\n",
      "    [pipeline] trial mode: params={'n_estimators': 67, 'learning_rate': 0.0657724068674459, 'max_depth': 4, 'num_leaves': 7, 'min_child_samples': 10}\n",
      "🗑️ 指定カラム削除: []\n",
      "🗑️ 高欠損率カラム削除: []\n",
      "🗑️ 低分散カラム削除: []\n",
      "🗑️ 指定カラム削除: []\n",
      "🗑️ 高欠損率カラム削除: []\n",
      "📊 削除対象カラム総数: 0 / 13\n",
      "📊 分類タスクを検出: f_classif使用\n",
      "📊 統計的特徴量選択: ['alcohol', 'malic_acid', 'alcalinity_of_ash', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "🗑️ 低分散カラム削除: []\n",
      "📊 削除対象カラム総数: 0 / 13\n",
      "📊 分類タスクを検出: f_classif使用\n",
      "📊 統計的特徴量選択: ['alcohol', 'malic_acid', 'alcalinity_of_ash', 'total_phenols', 'flavanoids', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 351\n",
      "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 359\n",
      "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "🗑️ 指定カラム削除: []\n",
      "🗑️ 高欠損率カラム削除: []\n",
      "🗑️ 低分散カラム削除: []\n",
      "📊 削除対象カラム総数: 0 / 13\n",
      "📊 分類タスクを検出: f_classif使用\n",
      "📊 統計的特徴量選択: ['alcohol', 'malic_acid', 'alcalinity_of_ash', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-22 23:02:16,007] Trial 0 finished with value: 0.9647047814229236 and parameters: {'n_estimators': 67, 'learning_rate': 0.0657724068674459, 'max_depth': 4, 'num_leaves': 7, 'min_child_samples': 10}. Best is trial 0 with value: 0.9647047814229236.\n"
     ]
    }
   ],
   "source": [
    "# MLflow実験セットアップ\n",
    "setup_mlflow_experiment(cfg)\n",
    "\n",
    "# 既存runがある場合は終了\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# カスタムRun名設定（オプション）\n",
    "run_name = getattr(cfg.mlflow, 'run_id', None)\n",
    "\n",
    "print(f\"🚀 MLflow実験開始\")\n",
    "print(f\"  - Experiment: {cfg.mlflow.experiment_name}\")\n",
    "print(f\"  - Run name: {run_name if run_name else '自動生成'}\")\n",
    "\n",
    "# 予測結果DataFrame保存用変数\n",
    "df_predictions = None\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    print(f\"  - Run ID: {run.info.run_id[:8]}\")\n",
    "    \n",
    "    # タグ設定（run開始後）\n",
    "    set_mlflow_tags(cfg)\n",
    "    \n",
    "    # Optuna最適化（有効な場合）\n",
    "    if cfg.optuna.enabled:\n",
    "        print(f\"\\n🎯 Optuna最適化開始\")\n",
    "        optimizer = OptunaOptimizer(cfg, X_train, y_train, task_type)\n",
    "        best_params, best_score = optimizer.optimize()\n",
    "        print(f\"🎯 Optuna best_params: {best_params}\")\n",
    "        print(f\"  ✅ 最適化完了\")\n",
    "    else:\n",
    "        best_params = {}\n",
    "        best_score = 0.0\n",
    "        print(f\"⚠️ Optuna無効: best_params = {best_params}\")\n",
    "        print(\"  ⚠️ Optuna最適化はスキップ\")\n",
    "    \n",
    "    # 最適化されたパイプライン構築（best_paramsを反映）\n",
    "    passed_params = best_params if best_params else None\n",
    "    print(f\"📦 create_pipeline呼び出し: best_params={passed_params}\")\n",
    "    print(f\"\\n🔧 パイプライン構築\")\n",
    "    best_pipeline = create_pipeline(cfg, best_params=passed_params)\n",
    "    print(f\"  - ステップ数: {len(best_pipeline.steps)}\")\n",
    "    for step_name, step_obj in best_pipeline.steps:\n",
    "        print(f\"    - {step_name}: {type(step_obj).__name__}\")\n",
    "    \n",
    "    # パイプライン学習\n",
    "    print(f\"\\n📈 モデル学習\")\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    print(f\"  ✅ 学習完了\")\n",
    "    \n",
    "    # 実行時パラメータ記録\n",
    "    log_runtime_parameters(best_pipeline, cfg, best_params)\n",
    "    \n",
    "    # テストデータ予測（1回のみ実行）\n",
    "    print(f\"\\n📊 テストデータ予測\")\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    print(f\"  ✅ 予測完了: {len(y_pred)}件\")\n",
    "    \n",
    "    # Optuna最適化時はCV評価済み、未実行時のみCV実行\n",
    "    if not cfg.optuna.enabled:\n",
    "        # クロスバリデーション評価（Optuna未使用時のみ）\n",
    "        print(f\"\\n🔄 クロスバリデーション評価\")\n",
    "        if task_type == \"classification\":\n",
    "            scoring = cfg.optuna.scoring.classification\n",
    "        else:\n",
    "            scoring = cfg.optuna.scoring.regression\n",
    "        \n",
    "        cv_strategy = create_cv_strategy(cfg)\n",
    "        print(f\"  - CV戦略: {cfg.evaluation.cv_strategy['class']} (n_splits={cfg.evaluation.cv_strategy.params.n_splits})\")\n",
    "        print(f\"  - 評価指標: {scoring}\")\n",
    "        \n",
    "        cv_scores = cross_val_score(\n",
    "            best_pipeline, X_train, y_train,\n",
    "            cv=cv_strategy,\n",
    "            scoring=scoring\n",
    "        )\n",
    "        print(f\"  - CVスコア: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "    else:\n",
    "        # Optuna使用時は最適化結果を使用\n",
    "        cv_scores = np.array([best_score] * 5)  # best_scoreを5foldに展開（numpy配列で互換性維持）\n",
    "        print(f\"\\n🔄 CV評価をスキップ（Optuna最適化済み: {best_score:.3f}）\")\n",
    "    \n",
    "    # メトリクス記録\n",
    "    print(f\"\\n📊 評価メトリクス計算\")\n",
    "    log_experiment_metrics(best_pipeline, X_train, y_train, X_test, y_test, task_type, cv_scores, y_pred=y_pred)\n",
    "    \n",
    "    # 予測結果DataFrame作成と保存\n",
    "    print(f\"\\n📊 予測結果DataFrame作成\")\n",
    "    df_predictions = create_prediction_dataframe(best_pipeline, X_test, y_test, task_type, y_pred=y_pred)\n",
    "    save_prediction_results(df_predictions, cfg)\n",
    "    \n",
    "    # 予測結果表示（既存の予測結果を使用）\n",
    "    if task_type == \"classification\":\n",
    "        from sklearn.metrics import accuracy_score, f1_score\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f\"  - Test Accuracy: {test_accuracy:.3f}\")\n",
    "        print(f\"  - Test F1 Score: {test_f1:.3f}\")\n",
    "    else:\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        test_mse = mean_squared_error(y_test, y_pred)\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"  - Test MSE: {test_mse:.3f}\")\n",
    "        print(f\"  - Test R²: {test_r2:.3f}\")\n",
    "    \n",
    "    # 可視化生成（config駆動）\n",
    "    if cfg.visualization.enabled:\n",
    "        print(f\"\\n📈 可視化生成\")\n",
    "        target_names_str = [str(name) for name in target_names]\n",
    "        create_visualizations(\n",
    "            best_pipeline, X_train, y_train, X_test, y_test,\n",
    "            target_names_str, cfg.visualization.plots, cfg, task_type\n",
    "        )\n",
    "        print(f\"  ✅ 可視化完了: {', '.join(cfg.visualization.plots)}\")\n",
    "    \n",
    "    # モデル・アーティファクト保存\n",
    "    print(f\"\\n💾 アーティファクト保存\")\n",
    "    save_model_artifacts(best_pipeline, feature_cols, target_names, cfg)\n",
    "    print(f\"  ✅ モデル・メタデータ保存完了\")\n",
    "    \n",
    "    print(f\"\\n✅ MLOps実験完了\")\n",
    "    print(f\"  - Run ID: {run.info.run_id}\")\n",
    "    print(f\"  - MLflow UI: http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 予測結果の確認と活用\n",
    "\n",
    "予測結果DataFrameを確認し、後続の分析に活用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果DataFrameの確認\n",
    "if df_predictions is not None:\n",
    "    print(\"📊 予測結果DataFrame情報\")\n",
    "    print(f\"  - データ件数: {len(df_predictions)}件\")\n",
    "    print(f\"  - カラム数: {len(df_predictions.columns)}列\")\n",
    "    \n",
    "    # 分類タスクの場合のカラム情報\n",
    "    if task_type == \"classification\":\n",
    "        proba_cols = [col for col in df_predictions.columns if col.startswith('proba_class_')]\n",
    "        print(f\"  - 確率カラム: {proba_cols}\")\n",
    "        print(f\"  - 信頼度カラム: prediction_confidence\")\n",
    "    \n",
    "    print(\"\\n📋 予測結果サンプル（先頭5件）:\")\n",
    "    display(df_predictions.head())\n",
    "else:\n",
    "    print(\"⚠️ 予測結果DataFrameがまだ作成されていません。上のセルを実行してください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測精度の詳細分析（分類タスクの例）\n",
    "if df_predictions is not None and task_type == \"classification\":\n",
    "    # 予測の信頼度分布\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # 信頼度ヒストグラム\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df_predictions['prediction_confidence'], bins=20, edgecolor='black')\n",
    "    plt.xlabel('予測信頼度')\n",
    "    plt.ylabel('件数')\n",
    "    plt.title('予測信頼度の分布')\n",
    "    \n",
    "    # 正誤別の信頼度\n",
    "    plt.subplot(1, 2, 2)\n",
    "    df_predictions['is_correct'] = df_predictions['y_true'] == df_predictions['y_pred']\n",
    "    correct_conf = df_predictions[df_predictions['is_correct']]['prediction_confidence']\n",
    "    incorrect_conf = df_predictions[~df_predictions['is_correct']]['prediction_confidence']\n",
    "    \n",
    "    plt.boxplot([correct_conf, incorrect_conf], labels=['正解', '不正解'])\n",
    "    plt.ylabel('予測信頼度')\n",
    "    plt.title('正誤別の予測信頼度')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 統計情報\n",
    "    print(\"📊 予測信頼度の統計:\")\n",
    "    print(f\"  - 全体平均: {df_predictions['prediction_confidence'].mean():.3f}\")\n",
    "    print(f\"  - 正解時平均: {correct_conf.mean():.3f}\")\n",
    "    print(f\"  - 不正解時平均: {incorrect_conf.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追加: データ分析とエクスポート\n",
    "\n",
    "予測結果DataFrameはそのまま後続の分析に利用可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 予測結果をローカルCSVとして保存（必要な場合）\n",
    "# if df_predictions is not None:\n",
    "#     output_path = \"test_predictions_local.csv\"\n",
    "#     df_predictions.to_csv(output_path, index=False)\n",
    "#     print(f\"✅ 予測結果をローカル保存: {output_path}\")\n",
    "    \n",
    "#     # 必要なカラムのみ抽出した例\n",
    "#     df_essential = df_predictions[['y_true', 'y_pred', 'prediction_confidence']]\n",
    "#     print(f\"\\n📋 エッセンシャル予測結果（y_true, y_pred, confidence）:\")\n",
    "#     display(df_essential.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow UIの起動\n",
    "\n",
    "実験結果を確認するには、ターミナルで以下を実行：\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "その後、ブラウザで http://localhost:5000 にアクセス"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
