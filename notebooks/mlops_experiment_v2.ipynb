{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… matplotlibè¨­å®šå®Œäº†\n"
     ]
    }
   ],
   "source": [
    "# matplotlibè¨­å®š\n",
    "import logging\n",
    "import matplotlib\n",
    "\n",
    "# ãƒ•ã‚©ãƒ³ãƒˆè­¦å‘ŠæŠ‘åˆ¶\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "\n",
    "# DejaVu Sansãƒ•ã‚©ãƒ³ãƒˆè¨­å®š\n",
    "matplotlib.rcParams['font.family'] = 'DejaVu Sans'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Ubuntu']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… matplotlibè¨­å®šå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOpså®Ÿé¨“å®Ÿè¡Œãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯\n",
    "\n",
    "configé§†å‹•ã®MLOpsãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿé¨“ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚\n",
    "\n",
    "## ã‚»ãƒ«æ§‹æˆ\n",
    "1. **Import** - å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "2. **ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»åˆ†å‰²** - CSVãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨train/teståˆ†å‰²\n",
    "3. **MLflowå®Ÿè¡Œ** - ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ã€å­¦ç¿’ã€è©•ä¾¡ã€è¨˜éŒ²\n",
    "4. **äºˆæ¸¬çµæœã®ç¢ºèªã¨æ´»ç”¨** - äºˆæ¸¬çµæœDataFrameã®ç¢ºèªã¨å¾Œç¶šåˆ†æ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\n"
     ]
    }
   ],
   "source": [
    "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import mlflow\n",
    "from omegaconf import OmegaConf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£\n",
    "from src.utils.data_utils import get_dataset_name, detect_task_type, load_csv_data\n",
    "from src.utils.cv_utils import create_cv_strategy\n",
    "\n",
    "# componentsæ©Ÿèƒ½ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from src.mlops.components.pipeline import create_pipeline\n",
    "from src.mlops.components.visualization import create_visualizations\n",
    "from src.mlops.components.optimization import OptunaOptimizer\n",
    "from src.mlops.components.artifacts import (\n",
    "    save_model_artifacts, log_experiment_metrics, \n",
    "    setup_mlflow_experiment, set_mlflow_tags, \n",
    "    log_config_parameters, log_runtime_parameters,\n",
    "    create_prediction_dataframe, save_prediction_results\n",
    ")\n",
    "\n",
    "print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configèª­ã¿è¾¼ã¿ãƒ»ãƒ‡ãƒ¼ã‚¿åˆ†å‰²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Configèª­ã¿è¾¼ã¿å®Œäº†\n",
      "  - Pipeline: universal_features\n",
      "  - Model: lightgbm\n",
      "  - CV Strategy: {'module': 'sklearn.model_selection', 'class': 'StratifiedKFold', 'params': {'n_splits': 3, 'shuffle': True, 'random_state': '${globals.random_state}'}}\n",
      "  - Optuna: æœ‰åŠ¹\n"
     ]
    }
   ],
   "source": [
    "# Configèª­ã¿è¾¼ã¿ï¼ˆHydraã®ä»£ã‚ã‚Šã«OmegaConfã§ç›´æ¥èª­ã¿è¾¼ã¿ï¼‰\n",
    "cfg = OmegaConf.load(\"config/config.yaml\")\n",
    "\n",
    "# pipelinesè¨­å®šã‚’èª­ã¿è¾¼ã‚“ã§ãƒãƒ¼ã‚¸\n",
    "pipeline_config = OmegaConf.load(f\"config/pipelines/{cfg.defaults[2].pipelines}.yaml\")\n",
    "cfg = OmegaConf.merge(cfg, pipeline_config)\n",
    "\n",
    "# modelsè¨­å®šã‚’èª­ã¿è¾¼ã‚“ã§ãƒãƒ¼ã‚¸\n",
    "model_config = OmegaConf.load(f\"config/models/classification/{cfg.defaults[1]['models/classification']}.yaml\")\n",
    "cfg = OmegaConf.merge(cfg, model_config)\n",
    "\n",
    "# notebookãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹ä¿®æ­£\n",
    "cfg.data.file_path = f\"{cfg.data.file_path}\"\n",
    "\n",
    "print(\"ğŸ“‹ Configèª­ã¿è¾¼ã¿å®Œäº†\")\n",
    "print(f\"  - Pipeline: {cfg.defaults[2].pipelines}\")\n",
    "print(f\"  - Model: {cfg.defaults[1]['models/classification']}\")\n",
    "print(f\"  - CV Strategy: {cfg.evaluation.cv_strategy}\")\n",
    "print(f\"  - Optuna: {'æœ‰åŠ¹' if cfg.optuna.enabled else 'ç„¡åŠ¹'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹\n",
      "ğŸ“Š CSV: _data/raw/wine_classification.csv - Shape: (178, 15) - Features: 13 - Classes: 3\n",
      "âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†\n",
      "  - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: _data/raw/wine_classification.csv\n",
      "  - ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: (178, 15)\n",
      "  - ç‰¹å¾´é‡æ•°: 13\n",
      "  - ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: classification\n",
      "  - Train/Test: 142/36\n"
     ]
    }
   ],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿\n",
    "print(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹\")\n",
    "df, feature_cols, target_names = load_csv_data(cfg)\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "X = df[feature_cols]\n",
    "y = df[cfg.data.target_column]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=cfg.data.test_size,\n",
    "    random_state=cfg.data.random_state\n",
    ")\n",
    "\n",
    "# ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—åˆ¤å®š\n",
    "task_type = detect_task_type(y)\n",
    "\n",
    "print(f\"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†\")\n",
    "print(f\"  - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {cfg.data.file_path}\")\n",
    "print(f\"  - ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape}\")\n",
    "print(f\"  - ç‰¹å¾´é‡æ•°: {len(feature_cols)}\")\n",
    "print(f\"  - ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒ—: {task_type}\")\n",
    "print(f\"  - Train/Test: {len(X_train)}/{len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MLflowå®Ÿé¨“å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ MLflowå®Ÿé¨“é–‹å§‹\n",
      "  - Experiment: config_driven_mlops\n",
      "  - Run name: stratified_cv_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-22 23:02:12,857] A new study created in memory with name: ml_optimization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Run ID: 1563ac16\n",
      "\n",
      "ğŸ¯ Optunaæœ€é©åŒ–é–‹å§‹\n",
      "ğŸ¯ Optunaæœ€é©åŒ–é–‹å§‹ | 2 trials | maximize\n",
      "    [pipeline] trial mode: params={'n_estimators': 67, 'learning_rate': 0.0657724068674459, 'max_depth': 4, 'num_leaves': 7, 'min_child_samples': 10}\n",
      "ğŸ—‘ï¸ æŒ‡å®šã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ—‘ï¸ é«˜æ¬ æç‡ã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ—‘ï¸ ä½åˆ†æ•£ã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ—‘ï¸ æŒ‡å®šã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ—‘ï¸ é«˜æ¬ æç‡ã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ“Š å‰Šé™¤å¯¾è±¡ã‚«ãƒ©ãƒ ç·æ•°: 0 / 13\n",
      "ğŸ“Š åˆ†é¡ã‚¿ã‚¹ã‚¯ã‚’æ¤œå‡º: f_classifä½¿ç”¨\n",
      "ğŸ“Š çµ±è¨ˆçš„ç‰¹å¾´é‡é¸æŠ: ['alcohol', 'malic_acid', 'alcalinity_of_ash', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "ğŸ—‘ï¸ ä½åˆ†æ•£ã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ“Š å‰Šé™¤å¯¾è±¡ã‚«ãƒ©ãƒ ç·æ•°: 0 / 13\n",
      "ğŸ“Š åˆ†é¡ã‚¿ã‚¹ã‚¯ã‚’æ¤œå‡º: f_classifä½¿ç”¨\n",
      "ğŸ“Š çµ±è¨ˆçš„ç‰¹å¾´é‡é¸æŠ: ['alcohol', 'malic_acid', 'alcalinity_of_ash', 'total_phenols', 'flavanoids', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 351\n",
      "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 359\n",
      "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "ğŸ—‘ï¸ æŒ‡å®šã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ—‘ï¸ é«˜æ¬ æç‡ã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ—‘ï¸ ä½åˆ†æ•£ã‚«ãƒ©ãƒ å‰Šé™¤: []\n",
      "ğŸ“Š å‰Šé™¤å¯¾è±¡ã‚«ãƒ©ãƒ ç·æ•°: 0 / 13\n",
      "ğŸ“Š åˆ†é¡ã‚¿ã‚¹ã‚¯ã‚’æ¤œå‡º: f_classifä½¿ç”¨\n",
      "ğŸ“Š çµ±è¨ˆçš„ç‰¹å¾´é‡é¸æŠ: ['alcohol', 'malic_acid', 'alcalinity_of_ash', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 347\n",
      "[LightGBM] [Info] Number of data points in the train set: 114, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-22 23:02:16,007] Trial 0 finished with value: 0.9647047814229236 and parameters: {'n_estimators': 67, 'learning_rate': 0.0657724068674459, 'max_depth': 4, 'num_leaves': 7, 'min_child_samples': 10}. Best is trial 0 with value: 0.9647047814229236.\n"
     ]
    }
   ],
   "source": [
    "# MLflowå®Ÿé¨“ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "setup_mlflow_experiment(cfg)\n",
    "\n",
    "# æ—¢å­˜runãŒã‚ã‚‹å ´åˆã¯çµ‚äº†\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# ã‚«ã‚¹ã‚¿ãƒ Runåè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "run_name = getattr(cfg.mlflow, 'run_id', None)\n",
    "\n",
    "print(f\"ğŸš€ MLflowå®Ÿé¨“é–‹å§‹\")\n",
    "print(f\"  - Experiment: {cfg.mlflow.experiment_name}\")\n",
    "print(f\"  - Run name: {run_name if run_name else 'è‡ªå‹•ç”Ÿæˆ'}\")\n",
    "\n",
    "# äºˆæ¸¬çµæœDataFrameä¿å­˜ç”¨å¤‰æ•°\n",
    "df_predictions = None\n",
    "\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    print(f\"  - Run ID: {run.info.run_id[:8]}\")\n",
    "    \n",
    "    # ã‚¿ã‚°è¨­å®šï¼ˆruné–‹å§‹å¾Œï¼‰\n",
    "    set_mlflow_tags(cfg)\n",
    "    \n",
    "    # Optunaæœ€é©åŒ–ï¼ˆæœ‰åŠ¹ãªå ´åˆï¼‰\n",
    "    if cfg.optuna.enabled:\n",
    "        print(f\"\\nğŸ¯ Optunaæœ€é©åŒ–é–‹å§‹\")\n",
    "        optimizer = OptunaOptimizer(cfg, X_train, y_train, task_type)\n",
    "        best_params, best_score = optimizer.optimize()\n",
    "        print(f\"ğŸ¯ Optuna best_params: {best_params}\")\n",
    "        print(f\"  âœ… æœ€é©åŒ–å®Œäº†\")\n",
    "    else:\n",
    "        best_params = {}\n",
    "        best_score = 0.0\n",
    "        print(f\"âš ï¸ Optunaç„¡åŠ¹: best_params = {best_params}\")\n",
    "        print(\"  âš ï¸ Optunaæœ€é©åŒ–ã¯ã‚¹ã‚­ãƒƒãƒ—\")\n",
    "    \n",
    "    # æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ï¼ˆbest_paramsã‚’åæ˜ ï¼‰\n",
    "    passed_params = best_params if best_params else None\n",
    "    print(f\"ğŸ“¦ create_pipelineå‘¼ã³å‡ºã—: best_params={passed_params}\")\n",
    "    print(f\"\\nğŸ”§ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰\")\n",
    "    best_pipeline = create_pipeline(cfg, best_params=passed_params)\n",
    "    print(f\"  - ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(best_pipeline.steps)}\")\n",
    "    for step_name, step_obj in best_pipeline.steps:\n",
    "        print(f\"    - {step_name}: {type(step_obj).__name__}\")\n",
    "    \n",
    "    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å­¦ç¿’\n",
    "    print(f\"\\nğŸ“ˆ ãƒ¢ãƒ‡ãƒ«å­¦ç¿’\")\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    print(f\"  âœ… å­¦ç¿’å®Œäº†\")\n",
    "    \n",
    "    # å®Ÿè¡Œæ™‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨˜éŒ²\n",
    "    log_runtime_parameters(best_pipeline, cfg, best_params)\n",
    "    \n",
    "    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ï¼ˆ1å›ã®ã¿å®Ÿè¡Œï¼‰\n",
    "    print(f\"\\nğŸ“Š ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿äºˆæ¸¬\")\n",
    "    y_pred = best_pipeline.predict(X_test)\n",
    "    print(f\"  âœ… äºˆæ¸¬å®Œäº†: {len(y_pred)}ä»¶\")\n",
    "    \n",
    "    # Optunaæœ€é©åŒ–æ™‚ã¯CVè©•ä¾¡æ¸ˆã¿ã€æœªå®Ÿè¡Œæ™‚ã®ã¿CVå®Ÿè¡Œ\n",
    "    if not cfg.optuna.enabled:\n",
    "        # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡ï¼ˆOptunaæœªä½¿ç”¨æ™‚ã®ã¿ï¼‰\n",
    "        print(f\"\\nğŸ”„ ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³è©•ä¾¡\")\n",
    "        if task_type == \"classification\":\n",
    "            scoring = cfg.optuna.scoring.classification\n",
    "        else:\n",
    "            scoring = cfg.optuna.scoring.regression\n",
    "        \n",
    "        cv_strategy = create_cv_strategy(cfg)\n",
    "        print(f\"  - CVæˆ¦ç•¥: {cfg.evaluation.cv_strategy['class']} (n_splits={cfg.evaluation.cv_strategy.params.n_splits})\")\n",
    "        print(f\"  - è©•ä¾¡æŒ‡æ¨™: {scoring}\")\n",
    "        \n",
    "        cv_scores = cross_val_score(\n",
    "            best_pipeline, X_train, y_train,\n",
    "            cv=cv_strategy,\n",
    "            scoring=scoring\n",
    "        )\n",
    "        print(f\"  - CVã‚¹ã‚³ã‚¢: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}\")\n",
    "    else:\n",
    "        # Optunaä½¿ç”¨æ™‚ã¯æœ€é©åŒ–çµæœã‚’ä½¿ç”¨\n",
    "        cv_scores = np.array([best_score] * 5)  # best_scoreã‚’5foldã«å±•é–‹ï¼ˆnumpyé…åˆ—ã§äº’æ›æ€§ç¶­æŒï¼‰\n",
    "        print(f\"\\nğŸ”„ CVè©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆOptunaæœ€é©åŒ–æ¸ˆã¿: {best_score:.3f}ï¼‰\")\n",
    "    \n",
    "    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²\n",
    "    print(f\"\\nğŸ“Š è©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—\")\n",
    "    log_experiment_metrics(best_pipeline, X_train, y_train, X_test, y_test, task_type, cv_scores, y_pred=y_pred)\n",
    "    \n",
    "    # äºˆæ¸¬çµæœDataFrameä½œæˆã¨ä¿å­˜\n",
    "    print(f\"\\nğŸ“Š äºˆæ¸¬çµæœDataFrameä½œæˆ\")\n",
    "    df_predictions = create_prediction_dataframe(best_pipeline, X_test, y_test, task_type, y_pred=y_pred)\n",
    "    save_prediction_results(df_predictions, cfg)\n",
    "    \n",
    "    # äºˆæ¸¬çµæœè¡¨ç¤ºï¼ˆæ—¢å­˜ã®äºˆæ¸¬çµæœã‚’ä½¿ç”¨ï¼‰\n",
    "    if task_type == \"classification\":\n",
    "        from sklearn.metrics import accuracy_score, f1_score\n",
    "        test_accuracy = accuracy_score(y_test, y_pred)\n",
    "        test_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f\"  - Test Accuracy: {test_accuracy:.3f}\")\n",
    "        print(f\"  - Test F1 Score: {test_f1:.3f}\")\n",
    "    else:\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        test_mse = mean_squared_error(y_test, y_pred)\n",
    "        test_r2 = r2_score(y_test, y_pred)\n",
    "        print(f\"  - Test MSE: {test_mse:.3f}\")\n",
    "        print(f\"  - Test RÂ²: {test_r2:.3f}\")\n",
    "    \n",
    "    # å¯è¦–åŒ–ç”Ÿæˆï¼ˆconfigé§†å‹•ï¼‰\n",
    "    if cfg.visualization.enabled:\n",
    "        print(f\"\\nğŸ“ˆ å¯è¦–åŒ–ç”Ÿæˆ\")\n",
    "        target_names_str = [str(name) for name in target_names]\n",
    "        create_visualizations(\n",
    "            best_pipeline, X_train, y_train, X_test, y_test,\n",
    "            target_names_str, cfg.visualization.plots, cfg, task_type\n",
    "        )\n",
    "        print(f\"  âœ… å¯è¦–åŒ–å®Œäº†: {', '.join(cfg.visualization.plots)}\")\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜\n",
    "    print(f\"\\nğŸ’¾ ã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜\")\n",
    "    save_model_artifacts(best_pipeline, feature_cols, target_names, cfg)\n",
    "    print(f\"  âœ… ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†\")\n",
    "    \n",
    "    print(f\"\\nâœ… MLOpså®Ÿé¨“å®Œäº†\")\n",
    "    print(f\"  - Run ID: {run.info.run_id}\")\n",
    "    print(f\"  - MLflow UI: http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. äºˆæ¸¬çµæœã®ç¢ºèªã¨æ´»ç”¨\n",
    "\n",
    "äºˆæ¸¬çµæœDataFrameã‚’ç¢ºèªã—ã€å¾Œç¶šã®åˆ†æã«æ´»ç”¨ã§ãã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# äºˆæ¸¬çµæœDataFrameã®ç¢ºèª\n",
    "if df_predictions is not None:\n",
    "    print(\"ğŸ“Š äºˆæ¸¬çµæœDataFrameæƒ…å ±\")\n",
    "    print(f\"  - ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df_predictions)}ä»¶\")\n",
    "    print(f\"  - ã‚«ãƒ©ãƒ æ•°: {len(df_predictions.columns)}åˆ—\")\n",
    "    \n",
    "    # åˆ†é¡ã‚¿ã‚¹ã‚¯ã®å ´åˆã®ã‚«ãƒ©ãƒ æƒ…å ±\n",
    "    if task_type == \"classification\":\n",
    "        proba_cols = [col for col in df_predictions.columns if col.startswith('proba_class_')]\n",
    "        print(f\"  - ç¢ºç‡ã‚«ãƒ©ãƒ : {proba_cols}\")\n",
    "        print(f\"  - ä¿¡é ¼åº¦ã‚«ãƒ©ãƒ : prediction_confidence\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ äºˆæ¸¬çµæœã‚µãƒ³ãƒ—ãƒ«ï¼ˆå…ˆé ­5ä»¶ï¼‰:\")\n",
    "    display(df_predictions.head())\n",
    "else:\n",
    "    print(\"âš ï¸ äºˆæ¸¬çµæœDataFrameãŒã¾ã ä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä¸Šã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# äºˆæ¸¬ç²¾åº¦ã®è©³ç´°åˆ†æï¼ˆåˆ†é¡ã‚¿ã‚¹ã‚¯ã®ä¾‹ï¼‰\n",
    "if df_predictions is not None and task_type == \"classification\":\n",
    "    # äºˆæ¸¬ã®ä¿¡é ¼åº¦åˆ†å¸ƒ\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # ä¿¡é ¼åº¦ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df_predictions['prediction_confidence'], bins=20, edgecolor='black')\n",
    "    plt.xlabel('äºˆæ¸¬ä¿¡é ¼åº¦')\n",
    "    plt.ylabel('ä»¶æ•°')\n",
    "    plt.title('äºˆæ¸¬ä¿¡é ¼åº¦ã®åˆ†å¸ƒ')\n",
    "    \n",
    "    # æ­£èª¤åˆ¥ã®ä¿¡é ¼åº¦\n",
    "    plt.subplot(1, 2, 2)\n",
    "    df_predictions['is_correct'] = df_predictions['y_true'] == df_predictions['y_pred']\n",
    "    correct_conf = df_predictions[df_predictions['is_correct']]['prediction_confidence']\n",
    "    incorrect_conf = df_predictions[~df_predictions['is_correct']]['prediction_confidence']\n",
    "    \n",
    "    plt.boxplot([correct_conf, incorrect_conf], labels=['æ­£è§£', 'ä¸æ­£è§£'])\n",
    "    plt.ylabel('äºˆæ¸¬ä¿¡é ¼åº¦')\n",
    "    plt.title('æ­£èª¤åˆ¥ã®äºˆæ¸¬ä¿¡é ¼åº¦')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # çµ±è¨ˆæƒ…å ±\n",
    "    print(\"ğŸ“Š äºˆæ¸¬ä¿¡é ¼åº¦ã®çµ±è¨ˆ:\")\n",
    "    print(f\"  - å…¨ä½“å¹³å‡: {df_predictions['prediction_confidence'].mean():.3f}\")\n",
    "    print(f\"  - æ­£è§£æ™‚å¹³å‡: {correct_conf.mean():.3f}\")\n",
    "    print(f\"  - ä¸æ­£è§£æ™‚å¹³å‡: {incorrect_conf.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¿½åŠ : ãƒ‡ãƒ¼ã‚¿åˆ†æã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ\n",
    "\n",
    "äºˆæ¸¬çµæœDataFrameã¯ãã®ã¾ã¾å¾Œç¶šã®åˆ†æã«åˆ©ç”¨å¯èƒ½ã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # äºˆæ¸¬çµæœã‚’ãƒ­ãƒ¼ã‚«ãƒ«CSVã¨ã—ã¦ä¿å­˜ï¼ˆå¿…è¦ãªå ´åˆï¼‰\n",
    "# if df_predictions is not None:\n",
    "#     output_path = \"test_predictions_local.csv\"\n",
    "#     df_predictions.to_csv(output_path, index=False)\n",
    "#     print(f\"âœ… äºˆæ¸¬çµæœã‚’ãƒ­ãƒ¼ã‚«ãƒ«ä¿å­˜: {output_path}\")\n",
    "    \n",
    "#     # å¿…è¦ãªã‚«ãƒ©ãƒ ã®ã¿æŠ½å‡ºã—ãŸä¾‹\n",
    "#     df_essential = df_predictions[['y_true', 'y_pred', 'prediction_confidence']]\n",
    "#     print(f\"\\nğŸ“‹ ã‚¨ãƒƒã‚»ãƒ³ã‚·ãƒ£ãƒ«äºˆæ¸¬çµæœï¼ˆy_true, y_pred, confidenceï¼‰:\")\n",
    "#     display(df_essential.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow UIã®èµ·å‹•\n",
    "\n",
    "å®Ÿé¨“çµæœã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œï¼š\n",
    "```bash\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "ãã®å¾Œã€ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:5000 ã«ã‚¢ã‚¯ã‚»ã‚¹"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
